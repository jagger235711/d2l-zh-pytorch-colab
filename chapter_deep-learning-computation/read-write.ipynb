{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec47e64",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 读写文件\n",
    "\n",
    "到目前为止，我们讨论了如何处理数据，\n",
    "以及如何构建、训练和测试深度学习模型。\n",
    "然而，有时我们希望保存训练的模型，\n",
    "以备将来在各种环境中使用（比如在部署中进行预测）。\n",
    "此外，当运行一个耗时较长的训练过程时，\n",
    "最佳的做法是定期保存中间结果，\n",
    "以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。\n",
    "因此，现在是时候学习如何加载和存储权重向量和整个模型了。\n",
    "\n",
    "## (**加载和保存张量**)\n",
    "\n",
    "对于单个张量，我们可以直接调用`load`和`save`函数分别读写它们。\n",
    "这两个函数都要求我们提供一个名称，`save`要求将要保存的变量作为输入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b319fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:42.668559Z",
     "iopub.status.busy": "2023-08-18T06:56:42.667248Z",
     "iopub.status.idle": "2023-08-18T06:56:43.728764Z",
     "shell.execute_reply": "2023-08-18T06:56:43.727885Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f44ac7",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "我们现在可以将存储在文件中的数据读回内存。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab53461",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:43.733002Z",
     "iopub.status.busy": "2023-08-18T06:56:43.732347Z",
     "iopub.status.idle": "2023-08-18T06:56:43.741208Z",
     "shell.execute_reply": "2023-08-18T06:56:43.740416Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d4a111",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "我们可以[**存储一个张量列表，然后把它们读回内存。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81027fe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:43.744676Z",
     "iopub.status.busy": "2023-08-18T06:56:43.744140Z",
     "iopub.status.idle": "2023-08-18T06:56:43.751376Z",
     "shell.execute_reply": "2023-08-18T06:56:43.750630Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y],'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b060dd48",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "我们甚至可以(**写入或读取从字符串映射到张量的字典**)。\n",
    "当我们要读取或写入模型中的所有权重时，这很方便。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fde1cb33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:43.754777Z",
     "iopub.status.busy": "2023-08-18T06:56:43.754313Z",
     "iopub.status.idle": "2023-08-18T06:56:43.761150Z",
     "shell.execute_reply": "2023-08-18T06:56:43.760369Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa857bf",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "## [**加载和保存模型参数**]\n",
    "\n",
    "保存单个权重向量（或其他张量）确实有用，\n",
    "但是如果我们想保存整个模型，并在以后加载它们，\n",
    "单独保存每个向量则会变得很麻烦。\n",
    "毕竟，我们可能有数百个参数散布在各处。\n",
    "因此，深度学习框架提供了内置函数来保存和加载整个网络。\n",
    "需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。\n",
    "例如，如果我们有一个3层多层感知机，我们需要单独指定架构。\n",
    "因为模型本身可以包含任意代码，所以模型本身难以序列化。\n",
    "因此，为了恢复模型，我们需要用代码生成架构，\n",
    "然后从磁盘加载参数。\n",
    "让我们从熟悉的多层感知机开始尝试一下。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2672b5c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:43.764609Z",
     "iopub.status.busy": "2023-08-18T06:56:43.764090Z",
     "iopub.status.idle": "2023-08-18T06:56:43.773070Z",
     "shell.execute_reply": "2023-08-18T06:56:43.772277Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ceed0",
   "metadata": {
    "origin_pos": 25
   },
   "source": [
    "接下来，我们[**将模型的参数存储在一个叫做“mlp.params”的文件中。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53c1315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:43.776452Z",
     "iopub.status.busy": "2023-08-18T06:56:43.775942Z",
     "iopub.status.idle": "2023-08-18T06:56:43.780387Z",
     "shell.execute_reply": "2023-08-18T06:56:43.779636Z"
    },
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df754a",
   "metadata": {
    "origin_pos": 30
   },
   "source": [
    "为了恢复模型，我们[**实例化了原始多层感知机模型的一个备份。**]\n",
    "这里我们不需要随机初始化模型参数，而是(**直接读取文件中存储的参数。**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5e1b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:43.783850Z",
     "iopub.status.busy": "2023-08-18T06:56:43.783240Z",
     "iopub.status.idle": "2023-08-18T06:56:43.789905Z",
     "shell.execute_reply": "2023-08-18T06:56:43.789164Z"
    },
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65076662",
   "metadata": {
    "origin_pos": 35
   },
   "source": [
    "由于两个实例具有相同的模型参数，在输入相同的`X`时，\n",
    "两个实例的计算结果应该相同。\n",
    "让我们来验证一下。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a25ba1f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T06:56:43.793400Z",
     "iopub.status.busy": "2023-08-18T06:56:43.792788Z",
     "iopub.status.idle": "2023-08-18T06:56:43.798329Z",
     "shell.execute_reply": "2023-08-18T06:56:43.797576Z"
    },
    "origin_pos": 37,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a65b1e2",
   "metadata": {
    "origin_pos": 39
   },
   "source": [
    "## 小结\n",
    "\n",
    "* `save`和`load`函数可用于张量对象的文件读写。\n",
    "* 我们可以通过参数字典保存和加载网络的全部参数。\n",
    "* 保存架构必须在代码中完成，而不是在参数中完成。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？\n",
    "1. 假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如想在一个新的网络中使用之前网络的前两层，该怎么做？\n",
    "1. 如何同时保存网络架构和参数？需要对架构加上什么限制？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d803f301",
   "metadata": {
    "origin_pos": 41,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1839)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa7278d",
   "metadata": {},
   "source": [
    "即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？\n",
    "\n",
    "解答：\n",
    "\n",
    "  1. 加速模型训练：存储模型参数可以避免每次重新训练模型时需要重复计算之前已经计算过的权重和偏置。\n",
    "\n",
    "  2. 节省内存空间：保存模型参数比保存完整的模型文件更加节省内存空间，这在处理大型模型或使用内存受限设备时尤为重要。\n",
    "\n",
    "  3. 便于共享和复现：存储模型参数可以方便地共享和复现已经训练好的模型，其他人可以直接加载这些参数并使用它们进行预测或微调。\n",
    "\n",
    "  4. 便于调试和分析：通过检查模型参数，可以更容易地诊断模型中存在的问题，并对其进行调整和优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "951ef24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden.weight', 'hidden.bias', 'output.weight', 'output.bias'])\n",
      "odict_keys(['hidden.weight', 'hidden.bias'])\n",
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class MLP(nn.Module):  # 定义 MLP 类\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)  # 定义隐藏层层，输入尺寸为 20，输出尺寸为 256\n",
    "        self.output = nn.Linear(256, 10)  # 定义输出层，输入尺寸为 256，输出尺寸为 10\n",
    "\n",
    "    def forward(self, x):  # 定义前向传播函数\n",
    "        return self.output(\n",
    "            F.relu(self.hidden(x))\n",
    "        )  # 使用 ReLU 激活函数，计算隐藏层和输出层的输出\n",
    "\n",
    "\n",
    "class MLP_new(nn.Module):  # 定义 MLP 类\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)  # 定义隐藏层层，输入尺寸为 20，输出尺寸为 256\n",
    "        self.output = nn.Linear(256, 10)  # 定义输出层，输入尺寸为 256，输出尺寸为 10\n",
    "\n",
    "    def forward(self, x):  # 定义前向传播函数\n",
    "        return self.output(\n",
    "            F.relu(self.hidden(x))\n",
    "        )  # 使用 ReLU 激活函数，计算隐藏层和输出层的输出\n",
    "\n",
    "\n",
    "net = MLP()  # 创建 MLP 的实例\n",
    "# torch.save(net.hidden.state_dict(), \"mlp.hidden.params\")  # 将隐藏层的参数保存到文件中\n",
    "torch.save(net.state_dict(), \"mlp.params\")  # 将整个 MLP 的参数保存到文件中\n",
    "clone = MLP_new()  # 创建另一个 MLP 的实例\n",
    "params = torch.load(\"mlp.params\")  # 加载已保存的参数\n",
    "print(params.keys())  # 输出参数字典的键，查看包含哪些参数\n",
    "new_params = OrderedDict(\n",
    "    {k: v for k, v in params.items() if k.startswith(\"hidden\")}\n",
    ")  # 只取出隐藏层的参数\n",
    "print(new_params.keys())  # 输出新参数字典的键，查看包含哪些参数\n",
    "\n",
    "new_model_dict=clone.state_dict()  # 获取克隆实例的参数字典\n",
    "new_model_dict.update(new_params)  # 更新克隆实例的参数字典，只包含隐藏层的参数\n",
    "clone.load_state_dict(new_model_dict)  # 加载更新后的参数\n",
    "\n",
    "print(\n",
    "    clone.hidden.weight == net.hidden.weight\n",
    ")  # 比较两个 MLP 实例的隐藏层权重是否相等，并输出结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929767b7",
   "metadata": {},
   "source": [
    "如何同时保存网络架构和参数？需要对架构加上什么限制？\n",
    "\n",
    "解答：\n",
    "\n",
    "  在PyTorch中，可以使用torch.save()函数同时保存网络架构和参数。为了保存网络架构，需要将模型的结构定义在一个Python类中，并将该类实例化为模型对象。此外，必须确保该类的构造函数不包含任何随机性质的操作，例如dropout层的随机丢弃率应该是固定的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fcfb494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[-0.2095,  0.1770,  0.0797,  ...,  0.1109,  0.2000,  0.0592],\n",
       "                      [-0.0994, -0.2184,  0.0044,  ...,  0.1986,  0.0438, -0.1765],\n",
       "                      [ 0.0687,  0.2009, -0.0650,  ...,  0.1985,  0.1109,  0.0996],\n",
       "                      ...,\n",
       "                      [-0.1450, -0.0409, -0.2229,  ...,  0.0962, -0.0852,  0.0895],\n",
       "                      [-0.1965,  0.0946, -0.2063,  ..., -0.1918, -0.0526, -0.1048],\n",
       "                      [ 0.1362, -0.0733, -0.0673,  ..., -0.1634, -0.0528,  0.0993]])),\n",
       "             ('hidden.bias',\n",
       "              tensor([-0.1575,  0.0742, -0.0903, -0.2047, -0.0717, -0.2089, -0.1728, -0.0802,\n",
       "                       0.1011, -0.2177, -0.1281,  0.1474, -0.2072, -0.2036,  0.1465, -0.0629,\n",
       "                       0.1974,  0.1116,  0.2170,  0.0650, -0.1202,  0.1384,  0.1374, -0.2117,\n",
       "                       0.1553, -0.2096, -0.0081,  0.1568, -0.0516,  0.1212, -0.0654, -0.0671,\n",
       "                       0.1205,  0.1506, -0.0217, -0.2072,  0.1973,  0.0086,  0.1428,  0.1729,\n",
       "                      -0.2146,  0.1421,  0.2159, -0.2055,  0.0702, -0.0216,  0.0249, -0.1332,\n",
       "                       0.2233,  0.2188, -0.0800, -0.0601, -0.1243, -0.1155, -0.0356, -0.2064,\n",
       "                       0.1562, -0.1986,  0.0361,  0.0631,  0.0356, -0.1569, -0.0223,  0.2196,\n",
       "                      -0.1826,  0.1021, -0.2085, -0.1261,  0.1191, -0.1300, -0.1094,  0.2014,\n",
       "                       0.0854, -0.0057, -0.1568, -0.1430, -0.0987,  0.1989,  0.1277,  0.1849,\n",
       "                      -0.0265, -0.0153,  0.1691,  0.2058,  0.1159,  0.1416,  0.1639,  0.0667,\n",
       "                      -0.2039,  0.0009,  0.2082,  0.1369,  0.1552, -0.0798,  0.0945,  0.1808,\n",
       "                       0.1896, -0.0920,  0.2017,  0.0145, -0.0320,  0.0867, -0.1392,  0.1484,\n",
       "                       0.1217,  0.1534, -0.1678,  0.0318, -0.0293, -0.0730,  0.2107, -0.0226,\n",
       "                       0.0165,  0.0584,  0.1977, -0.0069, -0.0740, -0.1044, -0.0286, -0.0996,\n",
       "                      -0.0258,  0.0621, -0.0187, -0.0738, -0.0028, -0.1869, -0.0396, -0.1080,\n",
       "                       0.1964, -0.0477, -0.1480, -0.1428, -0.0214,  0.1343,  0.1330, -0.0854,\n",
       "                       0.1668, -0.2151, -0.0591, -0.1288,  0.1116, -0.0133,  0.0175, -0.0649,\n",
       "                       0.1361, -0.1413,  0.0071,  0.0004,  0.2027, -0.0804, -0.0815,  0.2155,\n",
       "                      -0.1801,  0.2227,  0.0681,  0.0293, -0.1423,  0.0154,  0.0892,  0.1601,\n",
       "                      -0.0566, -0.0852, -0.0949, -0.0443, -0.1646, -0.1715, -0.1711,  0.0211,\n",
       "                       0.0808, -0.0810,  0.1430, -0.0853, -0.0108, -0.1539, -0.0680,  0.1179,\n",
       "                       0.2151,  0.1015,  0.0083,  0.1073, -0.1986, -0.1541,  0.0938,  0.2014,\n",
       "                      -0.0645,  0.1012,  0.0150, -0.1407,  0.0743,  0.2195,  0.1378, -0.0475,\n",
       "                       0.0678,  0.1245, -0.2050,  0.1729,  0.2070,  0.0548,  0.0321,  0.1229,\n",
       "                      -0.0294,  0.1618,  0.0448, -0.1173,  0.1658,  0.0952, -0.0224, -0.0952,\n",
       "                      -0.1115, -0.1356, -0.0865, -0.0188,  0.1354,  0.1615,  0.2013, -0.1017,\n",
       "                      -0.0407, -0.0176,  0.0964, -0.1738,  0.2106,  0.1220,  0.0153,  0.0004,\n",
       "                      -0.1354, -0.2030, -0.2057,  0.0676,  0.1461,  0.2185, -0.1131, -0.0389,\n",
       "                      -0.0153,  0.1086,  0.1070,  0.1935, -0.1220,  0.1037,  0.1943,  0.1963,\n",
       "                      -0.0182, -0.1912,  0.0075, -0.2212,  0.1903,  0.0069,  0.0238, -0.0746,\n",
       "                      -0.1735, -0.0232,  0.0622,  0.1534, -0.0647, -0.1867,  0.0011, -0.0678])),\n",
       "             ('output.weight',\n",
       "              tensor([[-0.0280,  0.0124,  0.0405,  ..., -0.0329, -0.0295, -0.0326],\n",
       "                      [ 0.0555, -0.0164, -0.0548,  ..., -0.0591,  0.0312,  0.0076],\n",
       "                      [ 0.0041, -0.0173,  0.0069,  ..., -0.0275, -0.0219,  0.0120],\n",
       "                      ...,\n",
       "                      [-0.0587,  0.0149,  0.0009,  ...,  0.0443, -0.0392,  0.0037],\n",
       "                      [-0.0150, -0.0123, -0.0533,  ...,  0.0255,  0.0595, -0.0456],\n",
       "                      [-0.0492,  0.0039, -0.0347,  ..., -0.0388,  0.0435,  0.0482]])),\n",
       "             ('output.bias',\n",
       "              tensor([ 0.0537, -0.0208, -0.0105,  0.0468, -0.0238,  0.0500, -0.0365,  0.0093,\n",
       "                       0.0308,  0.0592]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class MLP(nn.Module):  # 定义 MLP 类\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)  # 定义隐藏层层，输入尺寸为 20，输出尺寸为 256\n",
    "        self.output = nn.Linear(256, 10)  # 定义输出层，输入尺寸为 256，输出尺寸为 10\n",
    "\n",
    "    def forward(self, x):  # 定义前向传播函数\n",
    "        return self.output(\n",
    "            F.relu(self.hidden(x))\n",
    "        )  # 使用 ReLU 激活函数，计算隐藏层和输出层的输出\n",
    "\n",
    "\n",
    "net = MLP()\n",
    "\n",
    "# 存储模型\n",
    "torch.save(net.state_dict(), \"model.pt\")\n",
    "\n",
    "# 导入模型\n",
    "model = torch.load(\"model.pt\")\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

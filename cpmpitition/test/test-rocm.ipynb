{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c8091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 版本: 3.11.12 (main, Apr  9 2025, 04:04:00) [Clang 20.1.0 ]\n",
      "PyTorch 版本: 2.7.1+rocm6.3\n",
      "------------------------------\n",
      "GPU (CUDA/ROCm) 可用！\n",
      "GPU 数量: 1\n",
      "GPU 0: AMD Radeon RX 6750 GRE 12GB\n",
      "  计算能力 (Compute Capability): (10, 3)\n",
      "  总显存: 11.98 GB\n",
      "------------------------------\n",
      "成功将张量移动到 GPU: tensor([1., 2.], device='cuda:0')\n",
      "当前设备: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['HSA_OVERRIDE_GFX_VERSION'] = '10.3.0' # Adjust to your GPU's GFX version\n",
    "\n",
    "print(f\"Python 版本: {sys.version}\")\n",
    "print(f\"PyTorch 版本: {torch.__version__}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU (CUDA/ROCm) 可用！\")\n",
    "    print(f\"GPU 数量: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        try:\n",
    "            print(f\"  计算能力 (Compute Capability): {torch.cuda.get_device_capability(i)}\")\n",
    "        except Exception as cap_e:\n",
    "            print(f\"  无法获取计算能力: {cap_e}\")\n",
    "        try:\n",
    "            print(f\"  总显存: {torch.cuda.get_device_properties(i).total_memory / (1024**3):.2f} GB\")\n",
    "        except Exception as mem_e:\n",
    "             print(f\"  无法获取显存信息: {mem_e}\")\n",
    "else:\n",
    "    print(\"GPU (CUDA/ROCm) 不可用。请检查：\")\n",
    "    print(\"1. 是否安装了支持 GPU (CUDA 或 ROCm) 的 PyTorch 版本？\")\n",
    "    print(\"   (对于 AMD GPU, 需要 ROCm 版本的 PyTorch)\")\n",
    "    print(\"2. GPU 驱动是否正确安装？\")\n",
    "    print(\"   (对于 AMD GPU, 需要 AMD ROCm 驱动)\")\n",
    "    print(\"3. ROCm 版本是否与 PyTorch 版本兼容？\")\n",
    "    print(\"4. 你的 AMD GPU 型号是否被 ROCm 和 PyTorch 支持？\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        tensor = torch.tensor([1.0, 2.0]).cuda()\n",
    "        print(\"成功将张量移动到 GPU:\", tensor)\n",
    "        print(\"当前设备:\", tensor.device)\n",
    "    else:\n",
    "        print(\"无法将张量移动到 GPU，因为 GPU (CUDA/ROCm) 不可用。\")\n",
    "except Exception as e:\n",
    "    print(f\"尝试将张量移动到 GPU 时出错: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9e50b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Checking ROCM support...\n",
      "GOOD: ROCM devices found:  2\n",
      "Checking PyTorch...\n",
      "GOOD: PyTorch is working fine.\n",
      "Checking user groups...\n",
      "GOOD: The user jagger is in RENDER and VIDEO groups.\n",
      "GOOD: PyTorch ROCM support found.\n",
      "Testing PyTorch ROCM support...\n",
      "Everything fine! You can run PyTorch code inside of: \n",
      "--->  AMD Ryzen 5 7500F 6-Core Processor   \n",
      "--->  gfx1030            \n"
     ]
    }
   ],
   "source": [
    "import torch, grp, pwd, os, subprocess\n",
    "\n",
    "import os\n",
    "os.environ['HSA_OVERRIDE_GFX_VERSION'] = '10.3.0' # Adjust to your GPU's GFX version\n",
    "\n",
    "devices = []\n",
    "try:\n",
    "\tprint(\"\\n\\nChecking ROCM support...\")\n",
    "\tresult = subprocess.run(['rocminfo'], stdout=subprocess.PIPE)\n",
    "\tcmd_str = result.stdout.decode('utf-8')\n",
    "\tcmd_split = cmd_str.split('Agent ')\n",
    "\tfor part in cmd_split:\n",
    "\t\titem_single = part[0:1]\n",
    "\t\titem_double = part[0:2]\n",
    "\t\tif item_single.isnumeric() or item_double.isnumeric():\n",
    "\t\t\tnew_split = cmd_str.split('Agent '+item_double)\n",
    "\t\t\tdevice = new_split[1].split('Marketing Name:')[0].replace('  Name:                    ', '').replace('\\n','').replace('                  ','').split('Uuid:')[0].split('*******')[1]\n",
    "\t\t\tdevices.append(device)\n",
    "\tif len(devices) > 0:\n",
    "\t\tprint('GOOD: ROCM devices found: ', len(devices))\n",
    "\telse:\n",
    "\t\tprint('BAD: No ROCM devices found.')\n",
    "\n",
    "\tprint(\"Checking PyTorch...\")\n",
    "\tx = torch.rand(5, 3)\n",
    "\thas_torch = False\n",
    "\tlen_x = len(x)\n",
    "\tif len_x == 5:\n",
    "\t\thas_torch = True\n",
    "\t\tfor i in x:\n",
    "\t\t\tif len(i) == 3:\n",
    "\t\t\t\thas_torch = True\n",
    "\t\t\telse:\n",
    "\t\t\t\thas_torch = False\n",
    "\tif has_torch:\n",
    "\t\tprint('GOOD: PyTorch is working fine.')\n",
    "\telse:\n",
    "\t\tprint('BAD: PyTorch is NOT working.')\n",
    "\n",
    "\n",
    "\tprint(\"Checking user groups...\")\n",
    "\tuser = os.getlogin()\n",
    "\tgroups = [g.gr_name for g in grp.getgrall() if user in g.gr_mem]\n",
    "\tgid = pwd.getpwnam(user).pw_gid\n",
    "\tgroups.append(grp.getgrgid(gid).gr_name)\n",
    "\tif 'render' in groups and 'video' in groups:\n",
    "\t\tprint('GOOD: The user', user, 'is in RENDER and VIDEO groups.')\n",
    "\telse:\n",
    "\t\tprint('BAD: The user', user, 'is NOT in RENDER and VIDEO groups. This is necessary in order to PyTorch use HIP resources')\n",
    "\n",
    "\tif torch.cuda.is_available():\n",
    "\t\tprint(\"GOOD: PyTorch ROCM support found.\")\n",
    "\t\tt = torch.tensor([5, 5, 5], dtype=torch.int64, device='cuda')\n",
    "\t\tprint('Testing PyTorch ROCM support...')\n",
    "\t\tif str(t) == \"tensor([5, 5, 5], device='cuda:0')\":\n",
    "\t\t\tprint('Everything fine! You can run PyTorch code inside of: ')\n",
    "\t\t\tfor device in devices:\n",
    "\t\t\t\tprint('---> ', device)\n",
    "\telse:\n",
    "\t\tprint(\"BAD: PyTorch ROCM support NOT found.\")\n",
    "except:\n",
    "\tprint('Cannot find rocminfo command information. Unable to determine if AMDGPU drivers with ROCM support were installed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
